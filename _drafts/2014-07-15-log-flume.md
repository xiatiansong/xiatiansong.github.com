---
layout: post

title:  商家日志采集方案介绍

description: 商家日志采集方案介绍

keywords:  

category: spark

tags: [spark]

published: true

---

商家日志采集方案介绍

# 需求

采集商家日志并将其存入hadoop集群中，要求商家日志必须是半结构化或者结构化的数据。

日志中可能有的字段有：

```
商家id
城市id
访问日期：20140101
访问时间：2014-01-01 12:32:12
访问ip
client-key
url
REF
```

# 可选方案
目前常用的开源日志收集系统有Flume-NG、Chukwa、Scribe等。

- Flume-NG是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，目前已经是Apache的一个子项目。
- Scribe是Facebook开源的日志收集系统，它为日志的分布式收集，统一处理提供一个可扩展的，高容错的简单方案。
- Chukwa是一个非常新的开源项目，由于其属于hadoop系列产品，因而使用了很多hadoop的组件（用HDFS存储，用mapreduce处理数据），它提供了很多模块以支持hadoop集群日志分析。

Flume-NG和Scribe、Chukwa对比如下：

|对比项‍|Flume-NG‍|Scribe‍|Chukwa|
|----|----|----|----|
|语言|Java| c/c++ |Java|
|容错性|‍Agent和Collector间，Collector和Store间都有容错性，且提供三种级别的可靠性保证；|Agent和Collector间, Collector和Store之间有容错性；|agent定期记录已发送数据来提供容错|
|负载均衡‍|Agent和Collector间，Collector和Store间有LoadBalance和Failover两种模式|‍无|‍无|‍
|可扩展性‍|好‍|好‍|好|‍‍‍
|Agent丰富程度‍|提供丰富的Agent，包括avro/thrift socket, text, tail等‍|主要是thrift端口，侵入性太强|自带一些agent，如获取日志的agen‍|
|Store丰富程度‍|可以直接写hdfs, text, console, tcp；写hdfs时支持对text和sequence的压缩；‍|提供buffer, network, file(hdfs, text)等‍|直接支持hdfs‍|‍
|代码结构‍|系统框架好，模块分明，易于开发‍|代码简单|‍版本升级太快|

从以上对比，推荐使用Flume-NG来采集日志。一些使用Flume采集日志的方案介绍：

- [基于Flume的美团日志收集系统](http://tech.meituan.com/mt-log-system-arch.html)
- [flume-ng+Kafka+Storm+HDFS 实时系统搭建](http://blog.csdn.net/weijonathan/article/details/18301321)

## Flume

Flume的核心是把数据从数据源收集过来，再送到目的地。为了保证输送一定成功，在送到目的地之前，会先缓存数据，待数据真正到达目的地后，删除自己缓存的数据。
Flume传输的数据的基本单位是event，如果是文本文件，通常是一行记录，这也是事务的基本单位。
Flume运行的核心是agent。它是一个完整的数据收集工具，含有三个核心组件，分别是source、channel、sink。通过这些组件，event可以从一个地方流向另一个地方，如下图所示。

![](http://www.ibm.com/developerworks/opensource/library/bd-flumews/fig01.png)

Flume支持的数据源：

- console：监听用户编辑历史和快捷键输入，只在node_nowatch模式下可用
- stdin：监听标准输入，只在node_nowatch模式下可用，每行将作为一个event source
- text(“filename”)：将文件filename作为数据源，按行发送
- tail(“filename”)：探测filename新产生的数据，按行发送出去
- rpcSource(port)：由rpc框架(thrift/avro)监听tcp端口
- syslogTcp和syslogUdp：监听Udp、Tcp端口
- exec：执行指令
- tailDir：监听目录中的文件末尾，使用正则去选定需要监听的文件，recurseDepth为递归监听其下子目录的深度‍

# 方案介绍

## 自定义方案

周期性扫描日志文件（文件以时间为单位进行回滚）的改动，然后将其通过shell脚本或者ETL加载到HDFS中。

方案说明：

1. 该方案较为简单，当需要编写代码，难以维护
2. 该方案没有考虑可用性、可靠性、扩展性以及容错性等等

## 使用Flume方案

Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，使用Flume可以给Hadoop平台提供离线数据和Storm平台提供实时数据流，以下为使用Flume的日志采集方案架构图。

![](http://tech.meituan.com/img/mt-log-system/flume_base_arch.png)


整个系统分为三层：Agent层，Collector层和Store层。
a. Agent层每个机器部署一个进程，负责对单机的日志收集工作；Collector层部署在中心服务器上，负责接收Agent层发送的日志，并且将日志根据路由规则写到相应的Store层中；Store层负责提供永久或者临时的日志存储服务，或者将日志流导向其它服务器。

b. Agent到Collector使用LoadBalance策略，将所有的日志均衡地发到所有的Collector上，达到负载均衡的目标，同时并处理单个Collector失效的问题。

c. Collector层的目标主要有三个：SinkHdfs, SinkKafka和SinkBypass。分别提供离线的数据到Hdfs，和提供实时的日志流到Kafka（或者其他JMS中间件）和Bypass。

d. 对于Store来说，Hdfs负责永久地存储所有日志；Kafka存储最近的一段时间的日志，并可以给Storm系统提供实时日志流；Bypass负责给其它服务器和应用提供实时日志流。

### 相关技术

- Flume
- HDFS
- JMS
- Storm

### 架构设计
下面将从可用性，可靠性，可扩展性和兼容性等方面，对上述的架构做细致的解析。

a.可用性(availablity)

b.可靠性(reliability)

c.可扩展性(scalability)
