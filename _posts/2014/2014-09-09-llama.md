---
layout: post

title:  Llama的使用

description:   Llama (Low Latency Application MAster) 是一个 Yarn 的  Application Master，用于协调 Impala 和 Yarn 之间的集群资源的管理和监控。Llama 使 Impala 能够获取、使用和释放资源配额，而不需要 Impala 使用 Yarn 管理的 container 进程。Llama 提供了 Thrift API 来和 Yarn 交互。

keywords:  hadoop,yarn,impala,llama

category:  hadoop

tags: [llama,impala]

published: true

---

# 1. 介绍

 Llama (Low Latency Application MAster) 是一个 Yarn 的  Application Master，用于协调 Impala 和 Yarn 之间的集群资源的管理和监控。Llama 使 Impala 能够获取、使用和释放资源配额，而不需要 Impala 使用 Yarn 管理的 container 进程。Llama 提供了 Thrift API 来和 Yarn 交互。

个人理解，Llama 的作用就是使 Impala 能够工作在 YARN 之上，使得 Impala 和 YARN 共享集群资源，提供低延迟的查询。

-  Llama 官网地址：<http://cloudera.github.io/llama/>
-  Llama 源码：<https://github.com/cloudera/llama>

# 2. 架构

# 3. Llama 安装

## 2.1 安装 llama

Llama 需要安装在装有 Yarn 的节点上。

在 rhel 系统上安装：

```
$ sudo yum install llama-master
```

## 2.2 配置

> Llama 只能和 Yarn 配合工作，不能用于 MRv1。

Llama 的配置文件在 /etc/llama/conf/ 目录，llama-site.xml 默认配置在 <http://cloudera.github.io/llama/llama-site.html>。

## 2.3 启动和停止


启动：

```
$ sudo service llama start
```

停止：

```
$ sudo service llama stop
```

## 2.4 配置 HA

Llama 使用 Zookeeper 来实现 HA，任一时刻，只有一个 Llama-master 实例是 active的以确保资源不会被分区。

为了从 Yarn 获取资源，Llama 启动 YARN application 并且运行未管理的ApplicationMaster。当一个 Llama 实例宕掉的时候，分配给该实例启动的 application 的所有资源将会被回首，直到这些 application 超时（默认超时时间为10分钟）。当 Llama 运行失败的时候，这些资源将会被杀掉他启动的application的 Llama 回收。

HA 相关配置参数在 /etc/llama/conf/llama-site.xml：

|属性|描述|默认值|
|---|:---|:---:|
| `llama.am.cluster.id`|Cluster ID of the Llama pair, used to differentiate between different Llamas|llama|
| `llama.am.ha.enabled` |	Whether to enable Llama HA	| false	|
| `llama.am.ha.zk-quorum` |	ZooKeeper quorum to use for leader election and fencing	| |
| `llama.am.ha.zk-base` |	Base znode for leader election and fencing data	| /llama	|
| `llama.am.ha.zk-timeout-ms` |	The session timeout, in milliseconds, for connections to ZooKeeper quorum |	10000	|
| `llama.am.ha.zk-ac`l |	 ACLs to control access to ZooKeeper |	world:anyone:rwcda	|
| `llama.am.ha.zk-auth` |	Authorization information to go with the ACLs	| |

上面必填的两个参数为：

- `llama.am.ha.enabled` ： true
- `llama.am.ha.zk-quorum` ： cdh1:21088,cdh2:21088
  
## 2.5 修改 Impala 启动参数

使用 jdbc 方式提交查询到 Impala 时，会出现 `number of running queries 20 is over limit 20` 的异常，这时候在 impala的 源代码中搜索关键字 `number of running queries`，可以找到<https://github.com/cloudera/Impala/blob/cdh5-1.4_5.1.2/be/src/scheduling/admission-controller.cc>，从源代码中可以看到出现该问题和 Llama 有关系，在找不到 llama 的相关配置时，impala 一个队列中能够接受的最大请求数为 20。代码见:[RequestPoolService.java](https://github.com/cloudera/Impala/blob/c5c475712f88244e15160befaf4e99d6e165a148/fe/src/main/java/com/cloudera/impala/util/RequestPoolService.java)

```java
@VisibleForTesting
  TPoolConfigResult getPoolConfig(String pool) {
    TPoolConfigResult result = new TPoolConfigResult();
    int maxMemoryMb = allocationConf_.get().getMaxResources(pool).getMemory();
    result.setMem_limit(
        maxMemoryMb == Integer.MAX_VALUE ? -1 : (long) maxMemoryMb * ByteUnits.MEGABYTE);
    if (llamaConf_ == null) {												//llama配置为空
      result.setMax_requests(LLAMA_MAX_PLACED_RESERVATIONS_DEFAULT);
      result.setMax_queued(LLAMA_MAX_QUEUED_RESERVATIONS_DEFAULT);
    } else {
      // Capture the current llamaConf_ in case it changes while we're using it.
      Configuration currentLlamaConf = llamaConf_;
      result.setMax_requests(getLlamaPoolConfigValue(currentLlamaConf, pool,
          LLAMA_MAX_PLACED_RESERVATIONS_KEY,
          LLAMA_MAX_PLACED_RESERVATIONS_DEFAULT));  //20
      result.setMax_queued(getLlamaPoolConfigValue(currentLlamaConf, pool,
          LLAMA_MAX_QUEUED_RESERVATIONS_KEY,
          LLAMA_MAX_QUEUED_RESERVATIONS_DEFAULT));
    }
    LOG.trace("getPoolConfig(pool={}): mem_limit={}, max_requests={}, max_queued={}",
        new Object[] { pool, result.mem_limit, result.max_requests, result.max_queued });
    return result;
  }
```

目前，参考 [Admission Control and Query Queuing](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/Impala/Installing-and-Using-Impala/ciiu_admission.html)，在不安装和使用 llama 情况下，找到的一种解决办法是：

修改 impala 启动参数（/etc/default/impala），添加 ` -default_pool_max_requests=-1`，该参数设置每一个队列的最大请求数，如果为-1，则表示不做限制。

# 4. 使用

## 4.1 Llama Application Master

## 4.2 Llama Admin Command Line tool

## 4.3 Llama Node Manager Auxiliary Service

# 5. 参考文章

- [1] <http://cloudera.github.io/llama> 
- [2] [Admission Control and Query Queuing](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/Impala/Installing-and-Using-Impala/ciiu_admission.html)
