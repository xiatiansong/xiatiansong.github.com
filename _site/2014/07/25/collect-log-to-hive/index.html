<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>采集日志到Hive - 天松的个人博客</title>
  <meta name="description" content="我们现在的需求是需要将线上的日志以小时为单位采集并存储到 hive 数据库中，方便以后使用  mapreduce 或者 impala 做数据分析。为了实现这个目标调研了 flume 如何采集数据到 hive，其他的日志采集框架尚未做调研。">
  <meta name="keywords" content="hive">
  <meta name="author" content="天松">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
  <meta name="sogou_site_verification" content="ofwXWFdthV"/>

  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" >

  <link rel="canonical" href="http://blog.xiatiansong.com/2014/07/25/collect-log-to-hive">
  <link rel="stylesheet" href="/static/css/bootstrap.min.css" media="all">
  <link rel="stylesheet" href="/static/css/style.css" media="all">
  <link rel="stylesheet" href="/static/css/pygments.css" media="all">
  <link rel="stylesheet" href="/static/css/font-awesome.css" media="all">

  <!-- atom & rss feed -->
  <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="天松的个人博客 RSS Feed">
  <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="天松的个人博客 ATOM Feed">
</head>


  <body>
    <div class="container">
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<header class="header">
  <div class="title"><a title="天松的个人博客" href="/">天松的个人博客</a></div>
  <ul class="nav navbar-nav navbar-right visible-lg visible-md">
    <li>
    <form id="search-form" class="form-group has-success visible-lg" role="form">
      <input type="text" class="form-control input-sm" placeholder="Search" id="query" style="width: 160px;">
    </form>
    </li>
    <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
    <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
    <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
    <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
    
    <li><a href="https://github.com/xiatiansong" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
    
    
    
    
    
    <li><a href="http://weibo.com/xiaotian120" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
    

    <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
  </ul>
</header>


      <div class="wrapper">
        <div class="row">
          <div id="search-loader" style="display:none;text-align:center">
            <img src="http://javachen-rs.qiniudn.com/images/loading.gif">
          </div>
          <div class="col-md-12">
  <article class="news-item">

      <h2  class="news-item"> 采集日志到Hive  
        <time class="small">2014.07.25</time>
      </h2>

      <div><p>我们现在的需求是需要将线上的日志以小时为单位采集并存储到 hive 数据库中，方便以后使用  mapreduce 或者 impala 做数据分析。为了实现这个目标调研了 flume 如何采集数据到 hive，其他的日志采集框架尚未做调研。</p>

<h1 id="日志压缩">日志压缩</h1>

<p>flume中有个 HdfsSink 组件，其可以压缩日志进行保存，故首先想到我们的日志应该以压缩的方式进行保存，遂选择了 lzo 的压缩格式，HdfsSink 的配置如下:</p>
<div class="highlight"><pre><code class="language-properties" data-lang="properties"><span class="na">agent-1.sinks.sink_hdfs.channel</span> <span class="o">=</span> <span class="s">ch-1</span>
<span class="na">agent-1.sinks.sink_hdfs.type</span> <span class="o">=</span> <span class="s">hdfs</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.path</span> <span class="o">=</span> <span class="s">hdfs://cdh1:8020/user/root/events/%Y-%m-%d</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.filePrefix</span> <span class="o">=</span> <span class="s">logs</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.inUsePrefix</span> <span class="o">=</span> <span class="s">.</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.rollInterval</span> <span class="o">=</span> <span class="s">30</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.rollSize</span> <span class="o">=</span> <span class="s">0</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.rollCount</span> <span class="o">=</span> <span class="s">0</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.batchSize</span> <span class="o">=</span> <span class="s">1000</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.fileType</span> <span class="o">=</span> <span class="s">CompressedStream</span>
<span class="na">agent-1.sinks.sink_hdfs.hdfs.codeC</span> <span class="o">=</span> <span class="s">lzop</span>
</code></pre></div>
<p>hive 目前是支持 lzo 压缩的，但是要想在 mapreduce 中 lzo 文件可以拆分，需要通过 hadoop 的 api 进行手动创建索引：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>lzop a.txt
<span class="nv">$ </span>hadoop fs -put a.txt.lzo /log/dw_srclog/sp_visit_log/ptd_ymd<span class="o">=</span>20140720
​<span class="nv">$ </span>hadoop jar /usr/lib/hadoop/lib/hadoop-lzo.jar com.hadoop.compression.lzo.LzoIndexer /log/sp_visit_log/ptd_ymd<span class="o">=</span>20140720/a.txt.lzo
</code></pre></div>
<p>impala 目前也是在支持 lzo 压缩格式的文件的，故采用 lzo 压缩方式存储日志文件似乎是个可行方案。</p>

<h1 id="自定义分隔符">自定义分隔符</h1>

<p>Hive默认创建的表字段分隔符为：<code class="prettyprint">\001(ctrl-A)</code>，也可以通过 <code class="prettyprint">ROW FORMAT DELIMITED FIELDS TERMINATED BY</code> 指定其他字符，但是该语法只支持单个字符。</p>

<p>目前，我们的日志中几乎任何单个字符都被使用了，故没法使用单个字符作为 hive 表字段的分隔符，只能使用多个字符，例如：“|||”。<br>
使用多字符来分隔字段，则需要你自定义InputFormat来实现。</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">package</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">mapred</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.LongWritable</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.Text</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.FileSplit</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.InputSplit</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.JobConf</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.LineRecordReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.RecordReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.Reporter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapred.TextInputFormat</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyDemoInputFormat</span> <span class="kd">extends</span> <span class="n">TextInputFormat</span> <span class="o">{</span>

    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="n">RecordReader</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="n">getRecordReader</span><span class="o">(</span>
            <span class="n">InputSplit</span> <span class="n">genericSplit</span><span class="o">,</span> <span class="n">JobConf</span> <span class="n">job</span><span class="o">,</span> <span class="n">Reporter</span> <span class="n">reporter</span><span class="o">)</span>
            <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
        <span class="n">reporter</span><span class="o">.</span><span class="na">setStatus</span><span class="o">(</span><span class="n">genericSplit</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
        <span class="n">MyDemoRecordReader</span> <span class="n">reader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MyDemoRecordReader</span><span class="o">(</span>
                <span class="k">new</span> <span class="nf">LineRecordReader</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="o">(</span><span class="n">FileSplit</span><span class="o">)</span> <span class="n">genericSplit</span><span class="o">));</span>
        <span class="k">return</span> <span class="n">reader</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">MyDemoRecordReader</span> <span class="kd">implements</span>
            <span class="n">RecordReader</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="o">{</span>

        <span class="n">LineRecordReader</span> <span class="n">reader</span><span class="o">;</span>
        <span class="n">Text</span> <span class="n">text</span><span class="o">;</span>

        <span class="kd">public</span> <span class="nf">MyDemoRecordReader</span><span class="o">(</span><span class="n">LineRecordReader</span> <span class="n">reader</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">this</span><span class="o">.</span><span class="na">reader</span> <span class="o">=</span> <span class="n">reader</span><span class="o">;</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="na">createValue</span><span class="o">();</span>
        <span class="o">}</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">close</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
            <span class="n">reader</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
        <span class="o">}</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="n">LongWritable</span> <span class="nf">createKey</span><span class="o">()</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">reader</span><span class="o">.</span><span class="na">createKey</span><span class="o">();</span>
        <span class="o">}</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="n">Text</span> <span class="nf">createValue</span><span class="o">()</span> <span class="o">{</span>
            <span class="k">return</span> <span class="k">new</span> <span class="nf">Text</span><span class="o">();</span>
        <span class="o">}</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">long</span> <span class="nf">getPos</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">reader</span><span class="o">.</span><span class="na">getPos</span><span class="o">();</span>
        <span class="o">}</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">float</span> <span class="nf">getProgress</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">reader</span><span class="o">.</span><span class="na">getProgress</span><span class="o">();</span>
        <span class="o">}</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">next</span><span class="o">(</span><span class="n">LongWritable</span> <span class="n">key</span><span class="o">,</span> <span class="n">Text</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
            <span class="n">Text</span> <span class="n">txtReplace</span><span class="o">;</span>
            <span class="k">while</span> <span class="o">(</span><span class="n">reader</span><span class="o">.</span><span class="na">next</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">text</span><span class="o">))</span> <span class="o">{</span>
                <span class="n">txtReplace</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>
                <span class="n">txtReplace</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">text</span><span class="o">.</span><span class="na">toString</span><span class="o">().</span><span class="na">toLowerCase</span><span class="o">().</span><span class="na">replaceAll</span><span class="o">(</span><span class="s">&quot;\\|\\|\\|&quot;</span><span class="o">,</span> <span class="s">&quot;\001&quot;</span><span class="o">));</span>
                <span class="n">value</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">txtReplace</span><span class="o">.</span><span class="na">getBytes</span><span class="o">(),</span> <span class="mi">0</span><span class="o">,</span> <span class="n">txtReplace</span><span class="o">.</span><span class="na">getLength</span><span class="o">());</span>
                <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>

            <span class="o">}</span>
            <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>
<p>这时候的建表语句是：</p>
<div class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">create</span> <span class="k">external</span> <span class="k">table</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span>  <span class="n">test</span><span class="p">(</span>
<span class="n">id</span> <span class="n">string</span><span class="p">,</span>
<span class="n">name</span> <span class="n">string</span>
<span class="p">)</span><span class="n">partitioned</span> <span class="k">by</span> <span class="p">(</span><span class="k">day</span> <span class="n">string</span><span class="p">)</span> 
<span class="n">STORED</span> <span class="k">AS</span> <span class="n">INPUTFORMAT</span>  
  <span class="s1">&#39;org.apache.hadoop.mapred.MyDemoInputFormat&#39;</span>  
<span class="n">OUTPUTFORMAT</span>  
  <span class="s1">&#39;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&#39;</span>
<span class="k">LOCATION</span> <span class="s1">&#39;/log/dw_srclog/test&#39;</span><span class="p">;</span>
</code></pre></div>
<p>但是，这样建表的话，是不能识别 lzo 压缩文件的，需要去扩展 lzo 的 DeprecatedLzoTextInputFormat 类，但是如何扩展，没有找到合适方法。</p>

<p>所以，在自定义分隔符的情况下，想支持 lzo 压缩文件，需要另外想办法。例如，使用 <code class="prettyprint">SERDE</code> 的方式：</p>
<div class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">create</span> <span class="k">external</span> <span class="k">table</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span>  <span class="n">test</span><span class="p">(</span>
<span class="n">id</span> <span class="n">string</span><span class="p">,</span>
<span class="n">name</span> <span class="n">string</span>
<span class="p">)</span><span class="n">partitioned</span> <span class="k">by</span> <span class="p">(</span><span class="k">day</span> <span class="n">string</span><span class="p">)</span> 
<span class="k">ROW</span> <span class="n">FORMAT</span>  
<span class="n">SERDE</span> <span class="s1">&#39;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&#39;</span>  
<span class="k">WITH</span> <span class="n">SERDEPROPERTIES</span>  
<span class="p">(</span> <span class="s1">&#39;input.regex&#39;</span> <span class="o">=</span> <span class="s1">&#39;([^ ]*)\\|\\|\\|([^ ]*)&#39;</span><span class="p">,</span>  
<span class="s1">&#39;output.format.string&#39;</span> <span class="o">=</span> <span class="s1">&#39;%1$s %2$s&#39;</span><span class="p">)</span> 
<span class="n">STORED</span> <span class="k">AS</span> <span class="n">INPUTFORMAT</span>  
  <span class="s1">&#39;com.hadoop.mapred.DeprecatedLzoTextInputFormat&#39;</span>  
<span class="n">OUTPUTFORMAT</span>  
  <span class="s1">&#39;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&#39;</span>
<span class="k">LOCATION</span> <span class="s1">&#39;/log/dw_srclog/test&#39;</span><span class="p">;</span>
</code></pre></div>
<p>要想使用SERDE，必须添加 hive-contrib-XXXX.jar 到 classpath，在 hive-env.sh 中添加下面代码;</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span><span class="nb">export </span><span class="nv">HIVE_AUX_JARS_PATH</span><span class="o">=</span>/usr/lib/hive/lib/hive-contrib-0.10.0-cdh4.7.0.jar
</code></pre></div>
<p><strong>注意：</strong> </p>

<ul>
<li>使用 SERDE  时，字段类型只能为 string。</li>
<li>这种方式建表，flume 可以将日志存储为 lzo 并且 hive 能够识别出数据，但是 impala 中却不支持 <code class="prettyprint">SERDE</code> 的语法，故只能放弃该方法。</li>
</ul>

<p>最后，只能放弃 lzo 压缩文件的想法，改为不做压缩。flume 中 HdfsSink 配置参数 hdfs.fileType 目前只有三种可选值：CompressedStream<br>
、DataStream、SequenceFile，为了保持向后兼容便于扩展，这里使用了 DataStream 的方式，不做数据压缩。</p>

<h2 id="update">Update</h2>

<p><strong>注意：</strong></p>

<p>最后又经过测试，发现 impala 不支持 hive 的自定义文件格式，详细说明请参考：<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/Impala/latest/Installing-and-Using-Impala/ciiu_langref_unsupported.html?scroll=langref_unsupported">SQL Differences Between Impala and Hive</a></p>

<h1 id="日志采集">日志采集</h1>

<p>使用 flume 来采集日志，只需要在应用程序服务器上安装一个 agent 就可以监听文件或者目录的改变来搜集日志，但是实际情况你不一定有权限访问应用服务器，更多的方式是应用服务器将日志推送到一个中央的日志集中存储服务器。你只有权限去从该服务器收集数据，并且该服务器对外提供 ftp 的接口供你访问。</p>

<p>日志采集有 pull 和 push 的两种方式，关于两种方式的一些说明，可以参考这篇文章：<a href="http://sdjcw.iteye.com/blog/1814703">大规模日志收集处理项目的技术总结</a>。</p>

<p>对于当前情况而言，只能从 ftp 服务器轮询文件然后下载文件到本地，最后再将其导入到 hive 中去。以前，使用 kettle 做过这种事情，现在为了简单只是写了个 python 脚本来做这件事情，一个示例代码，请参考 <a href="https://gist.github.com/javachen/6f7d14aae138c7a284e6#file-fetch-py">https://gist.github.com/javachen/6f7d14aae138c7a284e6#file-fetch-py</a>。</p>

<p>该脚本会再 crontab 中每隔5分钟执行一次。</p>

<p>执行该脚本会往 mongodb 中记录一些状态信息，并往 logs 目录以天为单位记录日志。</p>

<p><strong>暂时没有使用 flume 的原因：</strong></p>

<ol>
<li>对 flume 的测试于调研程度还不够</li>
<li>flume 中无法对数据去重</li>
<li>只能停止 flume 进程，才可以升级 flume，这样会丢失数据</li>
</ol>

<p>等日志采集实时性要求变高，以及对 flume 的熟悉程度变深之后，会考虑使用 flume。</p>
</div>

      <!--
      <div id="pay" style="text-align:center;">
        ----EOF-----
        <br>
        <section>
  <h4>Sponsor</h4>
	<img src="http://javachen-rs.qiniudn.com/images/alipay.png" width="150/">
  <p class="small">觉得此博客对你有帮助，支付宝扫码赞助吧</p>
</section>

      </div>
      -->
      <p class="meta">
      	
            Categories:
      	    
          	<a class="btn btn-default btn-xs" href="/categories.html#hive">hive</a>
          
      	

      	
            Tags:
      	    
          	<a class="btn btn-default btn-xs" href="/tags.html#hive">hive</a>
          
          	<a class="btn btn-default btn-xs" href="/tags.html#flume">flume</a>
          
      	
      </p>
	</article>

	<ul class="pager">
	  
	  <li class="previous"><a class="btn btn-xs" href="/2014/07/22/flume-ng" title="Flume-ng的原理和使用">&larr; Prev</a></li>
	  
	  
	  <li class="next"><a class="btn btn-xs" href="/2014/07/28/phoenix-quick-start" title="Phoenix Quick Start">Next &rarr;</a></li>
	  
	</ul>

  
<div id="comments">
  <div class="ds-thread" data-thread-key="/2014/07/25/collect-log-to-hive"  data-title="采集日志到Hive - 天松的个人博客"></div>
</div>



</div>

        </div>
      </div>

      <footer class="footer text-center">
  <p>&copy; 2009-2015 <a href="/" target="_blank" title="86后，工作在深圳；Java程序员、Hadoop工程师；主要关注Java、Scala、Hadoop、Kettle、关注大数据处理技术。">天松</a>. With Help from <a href="//jekyllrb.com/" target="_blank" title="Transform your plain text into static websites and blogs.">Jekyll</a> and <a href="//getbootstrap.com/" target="_blank" title="Bootstrap is the most popular HTML, CSS, and JS framework for developing responsive, mobile first projects on the web.">Bootstrap</a>, theme from <a href="http://havee.me/" target="_blank" title="http://havee.me/">Havee</a>.

  <span style="float:right;"><a href="/about.html">About</a></span>

	
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254098866'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1254098866' type='text/javascript'%3E%3C/script%3E"));</script>




  </p>
  <div id="toTop" style="display: block;">
    <a href="#">▲</a><a href="#footer">▼</a>
  </div>
</footer>

    </div>

    <script src="/static/js/jquery.min.js"></script>
    <script src="/static/js/bootstrap.min.js"></script>
    <script src="/static/js/core.js"></script>

    
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254098866'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1254098866' type='text/javascript'%3E%3C/script%3E"));</script>




    
    <!-- duoshuo Begin -->
    <script type="text/javascript">
      var duoshuoQuery = {short_name:"sunshine1987"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
    </script>
    <!-- duoshuo End -->
    
  </body>
</html>
