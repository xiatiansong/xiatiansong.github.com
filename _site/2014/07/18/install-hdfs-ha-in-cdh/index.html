<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>CDH中配置HDFS HA - 天松的个人博客</title>
  <meta name="description" content="最近又安装 hadoop 集群， 故尝试了一下配置 HDFS 的 HA，这里使用的是 QJM 的 HA 方案。">
  <meta name="keywords" content="java, hadoop, hive, hbase, spark, linux, scala, python, mysql">
  <meta name="author" content="天松">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
  <meta name="sogou_site_verification" content="ofwXWFdthV"/>

  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" >

  <link rel="canonical" href="http://blog.xiatiansong.com/2014/07/18/install-hdfs-ha-in-cdh">
  <link rel="stylesheet" href="/static/css/bootstrap.min.css" media="all">
  <link rel="stylesheet" href="/static/css/style.css" media="all">
  <link rel="stylesheet" href="/static/css/pygments.css" media="all">
  <link rel="stylesheet" href="/static/css/font-awesome.css" media="all">

  <!-- atom & rss feed -->
  <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="天松的个人博客 RSS Feed">
  <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="天松的个人博客 ATOM Feed">
</head>


  <body>
    <div class="container">
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<header class="header">
  <div class="title"><a title="天松的个人博客" href="/">天松的个人博客</a></div>
  <ul class="nav navbar-nav navbar-right visible-lg visible-md">
    <li>
    <form id="search-form" class="form-group has-success visible-lg" role="form">
      <input type="text" class="form-control input-sm" placeholder="Search" id="query" style="width: 160px;">
    </form>
    </li>
    <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
    <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
    <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
    <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
    
    <li><a href="https://github.com/xiatiansong" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
    
    
    
    
    
    <li><a href="http://weibo.com/xiaotian120" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
    

    <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
  </ul>
</header>


      <div class="wrapper">
        <div class="row">
          <div id="search-loader" style="display:none;text-align:center">
            <img src="http://javachen-rs.qiniudn.com/images/loading.gif">
          </div>
          <div class="col-md-12">
  <article class="news-item">

      <h2  class="news-item"> CDH中配置HDFS HA  
        <time class="small">2014.07.18</time>
      </h2>

      <div><p>最近又安装 hadoop 集群， 故尝试了一下配置 HDFS 的 HA，这里使用的是 QJM 的 HA 方案。</p>

<p>关于 hadoop 集群的安装部署过程你可以参考 <a href="/2013/04/06/install-cloudera-cdh-by-yum/">使用yum安装CDH Hadoop集群</a> 或者 <a href="/2014/07/17/manual-install-cdh-hadoop/">手动安装 hadoop 集群的过程</a>。</p>

<h2 id="集群规划">集群规划</h2>

<p>我一共安装了三个节点的集群，对于 HA 方案来说，三个节点准备安装如下服务：</p>

<ul>
<li>cdh1：hadoop-hdfs-namenode(primary) 、hadoop-hdfs-journalnode、hadoop-hdfs-zkfc</li>
<li>cdh2：hadoop-hdfs-namenode(standby)、hadoop-hdfs-journalnode、hadoop-hdfs-zkfc</li>
<li>cdh3: hadoop-hdfs-journalnode</li>
</ul>

<p>根据上面规划，在对应节点上安装相应的服务。</p>

<h2 id="安装步骤">安装步骤</h2>

<h3 id="停掉集群">停掉集群</h3>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">​<span class="nv">$ </span>sh /opt/cmd.sh <span class="s1">&#39; for x in `ls /etc/init.d/|grep impala` ; do service $x stop ; done&#39;</span>
<span class="nv">$ </span>sh /opt/cmd.sh <span class="s1">&#39; for x in `ls /etc/init.d/|grep hive` ; do service $x stop ; done&#39;</span>
<span class="nv">$ </span>sh /opt/cmd.sh <span class="s1">&#39; for x in `ls /etc/init.d/|grep hbase` ; do service $x stop ; done&#39;</span>
<span class="nv">$ </span>sh /opt/cmd.sh <span class="s1">&#39; for x in `ls /etc/init.d/|grep hadoop` ; do service $x stop ; done&#39;</span>
</code></pre></div>
<h3 id="修改配置文件">修改配置文件</h3>

<p>修改/etc/hadoop/conf/core-site.xml，做如下修改：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://mycluster:8020<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>ha.zookeeper.quorum<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>
<p>修改/etc/hadoop/conf/hdfs-site.xml，删掉一些原来的 namenode 配置，增加如下：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="c">&lt;!--  hadoop  HA --&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.nameservices<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>mycluster<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.ha.namenodes.mycluster<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>nn1,nn2<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>cdh1:8020<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>cdh2:8020<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>cdh1:50070<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>cdh2:50070<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.shared.edits.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>qjournal://cdh1:8485;cdh2,cdh3:8485/mycluster<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.journalnode.edits.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/data/dfs/jn<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.ha.fencing.methods<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>sshfence(hdfs)<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/var/lib/hadoop-hdfs/.ssh/id_rsa<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.ha.automatic-failover.enabled<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<h3 id="同步配置文件">同步配置文件</h3>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>sh /opt/syn.sh /etc/hadoop/conf /etc/hadoop/
</code></pre></div>
<p>在journalnode的三个节点上创建目录：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s1">&#39;mkdir -p /data/dfs/nn /data/dfs/jn ; chown -R hdfs:hdfs /data/dfs&#39;</span>
<span class="nv">$ </span>ssh cdh2 <span class="s1">&#39;mkdir -p /data/dfs/jn ; chown -R hdfs:hdfs /data/dfs/jn&#39;</span>
<span class="nv">$ </span>ssh cdh3 <span class="s1">&#39;mkdir -p /data/dfs/jn ; chown -R hdfs:hdfs /data/dfs/jn&#39;</span>
</code></pre></div>
<h3 id="配置无密码登陆">配置无密码登陆</h3>

<p>在两个NN上配置hdfs用户间无密码登陆：</p>

<p>对于 cdh1： </p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>passwd hdfs
<span class="nv">$ </span>su - hdfs
<span class="nv">$ </span>ssh-keygen
<span class="nv">$ </span>ssh-copy-id  cdh2
</code></pre></div>
<p>对于 cdh2： </p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>passwd hdfs
<span class="nv">$ </span>su - hdfs
<span class="nv">$ </span>ssh-keygen
<span class="nv">$ </span>ssh-copy-id   cdh1
</code></pre></div>
<h3 id="启动journalnode">启动journalnode</h3>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s1">&#39;service hadoop-hdfs-journalnode start&#39;</span>
<span class="nv">$ </span>ssh cdh2 <span class="s1">&#39;service hadoop-hdfs-journalnode start&#39;</span>
<span class="nv">$ </span>ssh cdh3 <span class="s1">&#39;service hadoop-hdfs-journalnode start&#39;</span>
</code></pre></div>
<h3 id="格式化集群">格式化集群</h3>

<p>cdh1作为Active NameNode，先格式化：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s1">&#39;sudo -u hdfs hdfs namenode -format&#39;</span>
</code></pre></div>
<p>然后启动Active NameNode：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>service hadoop-hdfs-namenode start
</code></pre></div>
<h3 id="同步-standby-namenode">同步 Standby NameNode</h3>

<p>cdh2作为 Standby NameNode，在该节点运行：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>sudo -u hdfs hadoop namenode -bootstrapStandby
</code></pre></div>
<p>然后，启动 Standby NameNode：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>service hadoop-hdfs-namenode start
</code></pre></div>
<h3 id="配置自动切换">配置自动切换</h3>

<p>在两个NameNode上安装hadoop-hdfs-zkfc</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s1">&#39;yum install hadoop-hdfs-zkfc;&#39;</span>
<span class="nv">$ </span>ssh cdh2 <span class="s1">&#39;yum install hadoop-hdfs-zkfc;&#39;</span>
</code></pre></div>
<p>在任意一个NameNode上下面命令，其会创建一个znode用于自动故障转移。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>hdfs zkfc -formatZK
</code></pre></div>
<p>然后再两个 NameNode 节点上启动zkfc：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>service hadoop-hdfs-zkfc start
</code></pre></div>
<h3 id="其他操作">其他操作</h3>

<p>因为执行格式化操作，故需要在 hdfs 上创建一些目录并设置权限，请参考其他文章。</p>

<p>执行手动切换：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>sudo -u hdfs hdfs haadmin -failover nn1 nn2
</code></pre></div>
<p>查看某Namenode的状态：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>sudo -u hdfs hdfs haadmin -getServiceState nn2
<span class="nv">$ </span>sudo -u hdfs hdfs haadmin -getServiceState nn1
</code></pre></div>
<h2 id="配置hbase-ha">配置HBase HA</h2>

<p>先停掉 hbase，然后修改/etc/hbase/conf/hbase-site.xml，做如下修改：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Configure HBase to use the HA NameNode nameservice --&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>hbase.rootdir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://mycluster:8020/hbase<span class="nt">&lt;/value&gt;</span>       
  <span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>在 zookeeper 节点上运行/usr/lib/zookeeper/bin/zkCli.sh</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ls /hbase/splitlogs
<span class="nv">$ </span>rmr /hbase/splitlogs
</code></pre></div>
<p>最后启动 hbase 服务。</p>

<h2 id="配置-hive-ha">配置 Hive HA</h2>

<p>运行下面命令：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>metatool -listFSRoot  
hdfs://cdh1/user/hive/warehouse  
<span class="nv">$ </span>metatool -updateLocation hdfs://mycluster hdfs://cdh1 -tablePropKey avro.schema.url 
-serdePropKey schema.url  
<span class="nv">$ </span>metatool -listFSRoot 
hdfs://cdh1/user/hive/warehouse
</code></pre></div>
<h2 id="配置-impala">配置 Impala</h2>

<p>不需要做什么修改，但是一定要记住 core-site.xml 中fs.defaultFS参数值要带上端口号。</p>
</div>

      <!--
      <div id="pay" style="text-align:center;">
        ----EOF-----
        <br>
        <section>
  <h4>Sponsor</h4>
	<img src="http://javachen-rs.qiniudn.com/images/alipay.png" width="150/">
  <p class="small">觉得此博客对你有帮助，支付宝扫码赞助吧</p>
</section>

      </div>
      -->
      <p class="meta">
      	
            Categories:
      	    
          	<a class="btn btn-default btn-xs" href="/categories.html#hadoop">hadoop</a>
          
      	

      	
            Tags:
      	    
          	<a class="btn btn-default btn-xs" href="/tags.html#hadoop">hadoop</a>
          
      	
      </p>
	</article>

	<ul class="pager">
	  
	  <li class="previous"><a class="btn btn-xs" href="/2014/07/17/manual-install-cdh-hadoop" title="手动安装Hadoop集群的过程">&larr; Prev</a></li>
	  
	  
	  <li class="next"><a class="btn btn-xs" href="/2014/07/22/flume-ng" title="Flume-ng的原理和使用">Next &rarr;</a></li>
	  
	</ul>

  
<div id="comments">
  <div class="ds-thread" data-thread-key="/2014/07/18/install-hdfs-ha-in-cdh"  data-title="CDH中配置HDFS HA - 天松的个人博客"></div>
</div>



</div>

        </div>
      </div>

      <footer class="footer text-center">
  <p>&copy; 2009-2015 <a href="/" target="_blank" title="86后，工作在深圳；Java程序员、Hadoop工程师；主要关注Java、Scala、Hadoop、Kettle、关注大数据处理技术。">天松</a>. With Help from <a href="//jekyllrb.com/" target="_blank" title="Transform your plain text into static websites and blogs.">Jekyll</a> and <a href="//getbootstrap.com/" target="_blank" title="Bootstrap is the most popular HTML, CSS, and JS framework for developing responsive, mobile first projects on the web.">Bootstrap</a>, theme from <a href="http://havee.me/" target="_blank" title="http://havee.me/">Havee</a>.

  <span style="float:right;"><a href="/about.html">About</a></span>

	
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254098866'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1254098866' type='text/javascript'%3E%3C/script%3E"));</script>




  </p>
  <div id="toTop" style="display: block;">
    <a href="#">▲</a><a href="#footer">▼</a>
  </div>
</footer>

    </div>

    <script src="/static/js/jquery.min.js"></script>
    <script src="/static/js/bootstrap.min.js"></script>
    <script src="/static/js/core.js"></script>

    
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254098866'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1254098866' type='text/javascript'%3E%3C/script%3E"));</script>




    
    <!-- duoshuo Begin -->
    <script type="text/javascript">
      var duoshuoQuery = {short_name:"sunshine1987"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
    </script>
    <!-- duoshuo End -->
    
  </body>
</html>
