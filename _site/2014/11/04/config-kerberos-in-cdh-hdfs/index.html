<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>HDFS配置Kerberos认证 - 天松的个人博客</title>
  <meta name="description" content="记录 CDH Hadoop 集群上配置 HDFS 集成 Kerberos 的过程，包括 Kerberos 的安装和 Hadoop 相关配置修改说明。">
  <meta name="keywords" content="java, hadoop, hive, hbase, spark, linux, scala, python, mysql">
  <meta name="author" content="天松">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
  <meta name="sogou_site_verification" content="ofwXWFdthV"/>

  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" >

  <link rel="canonical" href="http://blog.xiatiansong.com/2014/11/04/config-kerberos-in-cdh-hdfs">
  <link rel="stylesheet" href="/static/css/bootstrap.min.css" media="all">
  <link rel="stylesheet" href="/static/css/style.css" media="all">
  <link rel="stylesheet" href="/static/css/pygments.css" media="all">
  <link rel="stylesheet" href="/static/css/font-awesome.css" media="all">

  <!-- atom & rss feed -->
  <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="天松的个人博客 RSS Feed">
  <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="天松的个人博客 ATOM Feed">
</head>


  <body>
    <div class="container">
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<header class="header">
  <div class="title"><a title="天松的个人博客" href="/">天松的个人博客</a></div>
  <ul class="nav navbar-nav navbar-right visible-lg visible-md">
    <li>
    <form id="search-form" class="form-group has-success visible-lg" role="form">
      <input type="text" class="form-control input-sm" placeholder="Search" id="query" style="width: 160px;">
    </form>
    </li>
    <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
    <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
    <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
    <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
    
    <li><a href="https://github.com/xiatiansong" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
    
    
    
    
    
    <li><a href="http://weibo.com/xiaotian120" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
    

    <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
  </ul>
</header>


      <div class="wrapper">
        <div class="row">
          <div id="search-loader" style="display:none;text-align:center">
            <img src="http://xiaotian120.qiniudn.com/images/loading.gif">
          </div>
          <div class="col-md-12">
  <article class="news-item">

      <h2  class="news-item"> HDFS配置Kerberos认证  
        <time class="small">2014.11.04</time>
      </h2>

      <div><p>本文主要记录 CDH Hadoop 集群上配置 HDFS 集成 Kerberos 的过程，包括 Kerberos 的安装和 Hadoop 相关配置修改说明。</p>

<blockquote>
<p>注意：</p>

<p>下面第一、二部分内容，摘抄自《<a href="https://github.com/zouhc/MyHadoop/blob/master/doc/Hadoop%E7%9A%84kerberos%E7%9A%84%E5%AE%9E%E8%B7%B5%E9%83%A8%E7%BD%B2.md">Hadoop的kerberos的实践部署</a>》，主要是为了对 Hadoop 的认证机制和 Kerberos 认证协议做个简单介绍。在此，对原作者表示感谢。</p>
</blockquote>

<h1 id="1.-hadoop-的认证机制">1. Hadoop 的认证机制</h1>

<p>简单来说，没有做 kerberos 认证的 Hadoop，只要有 client 端就能够连接上。而且，通过一个有 root 的权限的内网机器，通过创建对应的 linux 用户，就能够得到 Hadoop 集群上对应的权限。</p>

<p>而实行 Kerberos 后，任意机器的任意用户都必须现在 Kerberos 的 KDC 中有记录，才允许和集群中其它的模块进行通信。</p>

<p>详细介绍请参考 <a href="http://dongxicheng.org/mapreduce/hadoop-security/">Hadoop安全机制研究</a></p>

<h1 id="2.-kerberos-认证协议">2. Kerberos 认证协议</h1>

<p>Kerberos 是一种网络认证协议，其设计目标是通过密钥系统为客户机/服务器应用程序提供强大的认证服务。</p>

<p>使用 Kerberos 时，一个客户端需要经过三个步骤来获取服务:</p>

<ul>
<li><strong>认证</strong>：客户端向认证服务器发送一条报文，并获取一个含时间戳的 Ticket-Granting Ticket（TGT）。</li>
<li><strong>授权</strong>：客户端使用 TGT 向 Ticket-Granting Server（TGS）请求一个服务 Ticket。</li>
<li><strong>服务请求</strong>：客户端向服务器出示服务 Ticket ，以证实自己的合法性。</li>
</ul>

<p>为此，Kerberos 需要 The Key Distribution Centers（KDC）来进行认证。KDC 只有一个 Master，可以带多个 slaves 机器。slaves 机器仅进行普通验证。Mater 上做的修改需要自动同步到 slaves。</p>

<p>另外，KDC 需要一个 admin，来进行日常的管理操作。这个 admin 可以通过远程或者本地方式登录。</p>

<h1 id="3.-搭建-kerberos">3. 搭建 Kerberos</h1>

<h2 id="3.1-环境">3.1 环境</h2>

<p>我们在三个节点的服务器上安装 Kerberos，这三个节点上安装了 hadoop 集群，安装 hadoop 过程见：<a href="/2013/04/06/install-cloudera-cdh-by-yum/">使用yum安装CDH Hadoop集群</a>。这三个节点机器分布为：cdh1、cdh2、cdh3。</p>

<ul>
<li><strong>操作系统</strong>：CentOs 6.6</li>
<li><strong>运行用户</strong>：root</li>
</ul>

<h2 id="3.2-安装过程">3.2 安装过程</h2>

<h3 id="3.2.1-准备工作">3.2.1 准备工作</h3>

<p>确认添加主机名解析到 <code class="prettyprint">/etc/hosts</code> 文件中。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>cat /etc/hosts
127.0.0.1       localhost

192.168.56.121 cdh1
192.168.56.122 cdh2
192.168.56.123 cdh3
</code></pre></div>
<blockquote>
<p>注意：hostname 请使用小写，要不然在集成 kerberos 时会出现一些错误。</p>
</blockquote>

<h3 id="3.2.2-安装-kdc-server">3.2.2 安装 kdc server</h3>

<p>在 KDC (这里是 cdh1 ) 上安装包 krb5、krb5-server 和 krb5-client。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>yum install krb5-server krb5-libs krb5-auth-dialog krb5-workstation  -y
</code></pre></div>
<p>在其他节点（cdh1、cdh2、cdh3）安装 krb5-devel、krb5-workstation ：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s2">&quot;yum install krb5-devel krb5-workstation -y&quot;</span>
<span class="nv">$ </span>ssh cdh2 <span class="s2">&quot;yum install krb5-devel krb5-workstation -y&quot;</span>
<span class="nv">$ </span>ssh cdh3 <span class="s2">&quot;yum install krb5-devel krb5-workstation -y&quot;</span>
</code></pre></div>
<h3 id="3.2.3-修改配置文件">3.2.3 修改配置文件</h3>

<p>kdc 服务器涉及到三个配置文件：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/etc/krb5.conf
/var/kerberos/krb5kdc/kdc.conf
/var/kerberos/krb5kdc/kadm5.acl
</code></pre></div>
<p>配置 Kerberos 的一种方法是编辑配置文件 /etc/krb5.conf。默认安装的文件中包含多个示例项。</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">$ cat /etc/krb5.conf
  [logging]
   default = FILE:/var/log/krb5libs.log
   kdc = FILE:/var/log/krb5kdc.log
   admin_server = FILE:/var/log/kadmind.log

  [libdefaults]
   default_realm = JAVACHEN.COM
   dns_lookup_realm = false
   dns_lookup_kdc = false
   clockskew = 120
   ticket_lifetime = 24h
   renew_lifetime = 7d
   forwardable = true
   renewable = true
   udp_preference_limit = 1
   default_tgs_enctypes = arcfour-hmac
   default_tkt_enctypes = arcfour-hmac

  [realms]
   JAVACHEN.COM = {
    kdc = cdh1:88
    admin_server = cdh1:749
   }

  [domain_realm]
    .javachen.com = JAVACHEN.COM
    www.javachen.com = JAVACHEN.COM

  [kdc]
  profile=/var/kerberos/krb5kdc/kdc.conf
</code></pre></div>
<h3 id="说明：">说明：</h3>

<ul>
<li><code class="prettyprint">[logging]</code>：表示 server 端的日志的打印位置</li>
<li><code class="prettyprint">[libdefaults]</code>：每种连接的默认配置，需要注意以下几个关键的小配置

<ul>
<li><code class="prettyprint">default_realm = JAVACHEN.COM</code>：设置 Kerberos 应用程序的默认领域。如果您有多个领域，只需向 [realms] 节添加其他的语句。</li>
<li><code class="prettyprint">udp_preference_limit= 1</code>：禁止使用 udp 可以防止一个Hadoop中的错误</li>
<li><code class="prettyprint">clockskew</code>：时钟偏差是不完全符合主机系统时钟的票据时戳的容差，超过此容差将不接受此票据。通常，将时钟扭斜设置为 300 秒（5 分钟）。这意味着从服务器的角度看，票证的时间戳与它的偏差可以是在前后 5 分钟内。</li>
<li><code class="prettyprint">ticket_lifetime</code>： 表明凭证生效的时限，一般为24小时。</li>
<li><code class="prettyprint">renew_lifetime</code>： 表明凭证最长可以被延期的时限，一般为一个礼拜。当凭证过期之后，对安全认证的服务的后续访问则会失败。</li>
</ul></li>
<li><code class="prettyprint">[realms]</code>：列举使用的 realm。

<ul>
<li><code class="prettyprint">kdc</code>：代表要 kdc 的位置。格式是 <code class="prettyprint">机器:端口</code></li>
<li><code class="prettyprint">admin_server</code>：代表 admin 的位置。格式是 <code class="prettyprint">机器:端口</code></li>
<li><code class="prettyprint">default_domain</code>：代表默认的域名</li>
</ul></li>
<li><code class="prettyprint">[appdefaults]</code>：可以设定一些针对特定应用的配置，覆盖默认配置。</li>
</ul>

<p>修改 <code class="prettyprint">/var/kerberos/krb5kdc/kdc.conf</code> ，该文件包含 Kerberos 的配置信息。例如，KDC 的位置，Kerbero 的 admin 的realms 等。需要所有使用的 Kerberos 的机器上的配置文件都同步。这里仅列举需要的基本配置。详细介绍参考：<a href="http://web.mit.edu/%7Ekerberos/krb5-devel/doc/admin/conf_files/krb5_conf.html">krb5conf</a></p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>cat /var/kerberos/krb5kdc/kdc.conf
<span class="o">[</span>kdcdefaults<span class="o">]</span>
 <span class="nv">v4_mode</span> <span class="o">=</span> nopreauth
 <span class="nv">kdc_ports</span> <span class="o">=</span> 88
 <span class="nv">kdc_tcp_ports</span> <span class="o">=</span> 88

<span class="o">[</span>realms<span class="o">]</span>
 JAVACHEN.COM <span class="o">=</span> <span class="o">{</span>
  <span class="c">#master_key_type = aes256-cts</span>
  <span class="nv">acl_file</span> <span class="o">=</span> /var/kerberos/krb5kdc/kadm5.acl
  <span class="nv">dict_file</span> <span class="o">=</span> /usr/share/dict/words
  <span class="nv">admin_keytab</span> <span class="o">=</span> /var/kerberos/krb5kdc/kadm5.keytab
  <span class="nv">supported_enctypes</span> <span class="o">=</span>  des3-hmac-sha1:normal arcfour-hmac:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal des-cbc-crc:v4 des-cbc-crc:afs3
  <span class="nv">max_life</span> <span class="o">=</span> 24h
  <span class="nv">max_renewable_life</span> <span class="o">=</span> 10d
  <span class="nv">default_principal_flags</span> <span class="o">=</span> +renewable, +forwardable
 <span class="o">}</span>
</code></pre></div>
<h3 id="说明：">说明：</h3>

<ul>
<li><code class="prettyprint">JAVACHEN.COM</code>： 是设定的 realms。名字随意。Kerberos 可以支持多个 realms，会增加复杂度。大小写敏感，一般为了识别使用全部大写。这个 realms 跟机器的 host 没有大关系。</li>
<li><code class="prettyprint">master_key_type</code>：和 <code class="prettyprint">supported_enctypes</code> 默认使用 <code class="prettyprint">aes256-cts</code>。由于，JAVA 使用 <code class="prettyprint">aes256-cts</code> 验证方式需要安装额外的 jar 包（后面再做说明）。推荐不使用，并且删除 aes256-cts。</li>
<li><code class="prettyprint">acl_file</code>：标注了 admin 的用户权限，需要用户自己创建。文件格式是：<code class="prettyprint">Kerberos_principal permissions [target_principal]  [restrictions]</code></li>
<li><code class="prettyprint">supported_enctypes</code>：支持的校验方式。</li>
<li><code class="prettyprint">admin_keytab</code>：KDC 进行校验的 keytab。</li>
</ul>

<blockquote>
<p><strong>关于AES-256加密</strong>：</p>

<p>对于使用 centos5. 6及以上的系统，默认使用 AES-256 来加密的。这就需要集群中的所有节点上安装 <a href="http://www.oracle.com/technetwork/java/javase/downloads/jce-6-download-429243.html">Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy File</a>。</p>

<p>下载的文件是一个 zip 包，解开后，将里面的两个文件放到下面的目录中：<code class="prettyprint">$JAVA_HOME/jre/lib/security</code></p>
</blockquote>

<p>为了能够不直接访问 KDC 控制台而从 Kerberos 数据库添加和删除主体，请对 Kerberos 管理服务器指示允许哪些主体执行哪些操作。通过编辑文件 /var/lib/kerberos/krb5kdc/kadm5.acl 完成此操作。ACL（访问控制列表）允许您精确指定特权。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>cat /var/kerberos/krb5kdc/kadm5.acl
  */admin@JAVACHEN.COM *
</code></pre></div>
<h3 id="3.2.4-同步配置文件">3.2.4 同步配置文件</h3>

<p>将 kdc 中的 <code class="prettyprint">/etc/krb5.conf</code> 拷贝到集群中其他服务器即可。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>scp /etc/krb5.conf cdh2:/etc/krb5.conf
<span class="nv">$ </span>scp /etc/krb5.conf cdh3:/etc/krb5.conf
</code></pre></div>
<p>请确认集群如果关闭了 selinux。</p>

<h3 id="3.2.5-创建数据库">3.2.5 创建数据库</h3>

<p>在 cdh1 上运行初始化数据库命令。其中 <code class="prettyprint">-r</code> 指定对应 realm。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kdb5_util create -r JAVACHEN.COM -s
</code></pre></div>
<p>出现 <code class="prettyprint">Loading random data</code> 的时候另开个终端执行点消耗CPU的命令如 <code class="prettyprint">cat /dev/sda &gt; /dev/urandom</code> 可以加快随机数采集。</p>

<p>该命令会在 <code class="prettyprint">/var/kerberos/krb5kdc/</code> 目录下创建 principal 数据库。</p>

<p>如果遇到数据库已经存在的提示，可以把 <code class="prettyprint">/var/kerberos/krb5kdc/</code> 目录下的 principal 的相关文件都删除掉。默认的数据库名字都是 principal。可以使用 <code class="prettyprint">-d</code> 指定数据库名字。</p>

<h3 id="3.2.6-启动服务">3.2.6 启动服务</h3>

<p>在 cdh1 节点上运行：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>chkconfig --level 35 krb5kdc on
<span class="nv">$ </span>chkconfig --level 35 kadmin on
<span class="nv">$ </span>service krb5kdc start
<span class="nv">$ </span>service kadmin start
</code></pre></div>
<h3 id="3.2.7-创建-kerberos-管理员">3.2.7 创建 kerberos 管理员</h3>

<p>关于 kerberos 的管理，可以使用 <code class="prettyprint">kadmin.local</code> 或 <code class="prettyprint">kadmin</code>，至于使用哪个，取决于账户和访问权限：</p>

<ul>
<li>如果有访问 kdc 服务器的 root 权限，但是没有 kerberos admin 账户，使用 <code class="prettyprint">kadmin.local</code></li>
<li>如果没有访问 kdc 服务器的 root 权限，但是用 kerberos admin 账户，使用 <code class="prettyprint">kadmin</code></li>
</ul>

<p>在 cdh1 上创建远程管理的管理员：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#手动输入两次密码，这里密码为 root</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;addprinc root/admin&quot;</span>

<span class="c"># 也可以不用手动输入密码</span>
<span class="nv">$ </span><span class="nb">echo</span> -e <span class="s2">&quot;root\nroot&quot;</span> <span class="p">|</span> kadmin.local -q <span class="s2">&quot;addprinc root/admin&quot;</span>
</code></pre></div>
<p>系统会提示输入密码，密码不能为空，且需妥善保存。</p>

<h3 id="3.2.8-测试-kerberos">3.2.8 测试 kerberos</h3>

<blockquote>
<p>以下内容仅仅是为了测试，你可以直接跳到下部分内容。</p>
</blockquote>

<p>查看当前的认证用户：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># 查看principals</span>
<span class="nv">$ </span>kadmin: list_principals

  <span class="c"># 添加一个新的 principal</span>
  kadmin:  addprinc user1
    WARNING: no policy specified <span class="k">for </span>user1@JAVACHEN.COM<span class="p">;</span> defaulting to no policy
    Enter password <span class="k">for </span>principal <span class="s2">&quot;user1@JAVACHEN.COM&quot;</span>:
    Re-enter password <span class="k">for </span>principal <span class="s2">&quot;user1@JAVACHEN.COM&quot;</span>:
    Principal <span class="s2">&quot;user1@JAVACHEN.COM&quot;</span> created.

  <span class="c"># 删除 principal</span>
  kadmin:  delprinc user1
    Are you sure you want to delete the principal <span class="s2">&quot;user1@JAVACHEN.COM&quot;</span>? <span class="o">(</span>yes/no<span class="o">)</span>: yes
    Principal <span class="s2">&quot;user1@JAVACHEN.COM&quot;</span> deleted.
    Make sure that you have removed this principal from all ACLs before reusing.

  kadmin: <span class="nb">exit</span>
</code></pre></div>
<p>也可以直接通过下面的命令来执行：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># 提示需要输入密码</span>
<span class="nv">$ </span>kadmin -p root/admin -q <span class="s2">&quot;list_principals&quot;</span>
<span class="nv">$ </span>kadmin -p root/admin -q <span class="s2">&quot;addprinc user2&quot;</span>
<span class="nv">$ </span>kadmin -p root/admin -q <span class="s2">&quot;delprinc user2&quot;</span>

<span class="c"># 不用输入密码</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;list_principals&quot;</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;addprinc user2&quot;</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;delprinc user2&quot;</span>
</code></pre></div>
<p>创建一个测试用户 test，密码设置为 test：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span><span class="nb">echo</span> -e <span class="s2">&quot;test\ntest&quot;</span> <span class="p">|</span> kadmin.local -q <span class="s2">&quot;addprinc test&quot;</span>
</code></pre></div>
<p>获取 test 用户的 ticket：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># 通过用户名和密码进行登录</span>
<span class="nv">$ </span>kinit <span class="nb">test</span>
Password <span class="k">for </span><span class="nb">test</span>@JAVACHEN.COM:

<span class="nv">$ </span>klist  -e
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: <span class="nb">test</span>@JAVACHEN.COM

Valid starting     Expires            Service principal
11/07/14 15:29:02  11/08/14 15:29:02  krbtgt/JAVACHEN.COM@JAVACHEN.COM
  renew <span class="k">until </span>11/17/14 15:29:02, Etype <span class="o">(</span>skey, tkt<span class="o">)</span>: AES-128 CTS mode with 96-bit SHA-1 HMAC, AES-128 CTS mode with 96-bit SHA-1 HMAC


Kerberos 4 ticket cache: /tmp/tkt0
klist: You have no tickets cached
</code></pre></div>
<p>销毁该 test 用户的 ticket：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kdestroy

<span class="nv">$ </span>klist
klist: No credentials cache found <span class="o">(</span>ticket cache FILE:/tmp/krb5cc_0<span class="o">)</span>


Kerberos 4 ticket cache: /tmp/tkt0
klist: You have no tickets cached
</code></pre></div>
<p>更新 ticket：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kinit root/admin
  Password <span class="k">for </span>root/admin@JAVACHEN.COM:

<span class="nv">$ </span> klist
  Ticket cache: FILE:/tmp/krb5cc_0
  Default principal: root/admin@JAVACHEN.COM

  Valid starting     Expires            Service principal
  11/07/14 15:33:57  11/08/14 15:33:57  krbtgt/JAVACHEN.COM@JAVACHEN.COM
    renew <span class="k">until </span>11/17/14 15:33:57

  Kerberos 4 ticket cache: /tmp/tkt0
  klist: You have no tickets cached

<span class="nv">$ </span>kinit -R

<span class="nv">$ </span>klist
  Ticket cache: FILE:/tmp/krb5cc_0
  Default principal: root/admin@JAVACHEN.COM

  Valid starting     Expires            Service principal
  11/07/14 15:34:05  11/08/14 15:34:05  krbtgt/JAVACHEN.COM@JAVACHEN.COM
    renew <span class="k">until </span>11/17/14 15:33:57

  Kerberos 4 ticket cache: /tmp/tkt0
  klist: You have no tickets cached
</code></pre></div>
<p>抽取密钥并将其储存在本地 keytab 文件 /etc/krb5.keytab 中。这个文件由超级用户拥有，所以您必须是 root 用户才能在 kadmin shell 中执行以下命令：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;ktadd kadmin/admin&quot;</span>

<span class="nv">$ </span>klist -k /etc/krb5.keytab
  Keytab name: FILE:/etc/krb5.keytab
  KVNO Principal
  ---- --------------------------------------------------------------------------
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
     3 kadmin/admin@LASHOU-INC.COM
</code></pre></div>
<h1 id="4.-hdfs-上配置-kerberos">4. HDFS 上配置 kerberos</h1>

<h2 id="4.1-创建认证规则">4.1 创建认证规则</h2>

<p>在 Kerberos 安全机制里，一个 principal 就是 realm 里的一个对象，一个 principal 总是和一个密钥（secret key）成对出现的。</p>

<p>这个 principal 的对应物可以是 service，可以是 host，也可以是 user，对于 Kerberos 来说，都没有区别。</p>

<p>Kdc(Key distribute center) 知道所有 principal 的 secret key，但每个 principal 对应的对象只知道自己的那个 secret key 。这也是“共享密钥“的由来。</p>

<p>对于 hadoop，principals 的格式为 <code class="prettyprint">username/fully.qualified.domain.name@YOUR-REALM.COM</code>。</p>

<p>通过 yum 源安装的 cdh 集群中，NameNode 和 DataNode 是通过 hdfs 启动的，故为集群中每个服务器节点添加两个principals：hdfs、HTTP。</p>

<p>在 KCD server 上（这里是 cdh1）创建 hdfs principal：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">kadmin.local -q <span class="s2">&quot;addprinc -randkey hdfs/cdh1@JAVACHEN.COM&quot;</span>
kadmin.local -q <span class="s2">&quot;addprinc -randkey hdfs/cdh2@JAVACHEN.COM&quot;</span>
kadmin.local -q <span class="s2">&quot;addprinc -randkey hdfs/cdh3@JAVACHEN.COM&quot;</span>
</code></pre></div>
<p><code class="prettyprint">-randkey</code> 标志没有为新 principal 设置密码，而是指示 kadmin 生成一个随机密钥。之所以在这里使用这个标志，是因为此 principal 不需要用户交互。它是计算机的一个服务器帐户。</p>

<p>创建 HTTP principal：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">kadmin.local -q <span class="s2">&quot;addprinc -randkey HTTP/cdh1@JAVACHEN.COM&quot;</span>
kadmin.local -q <span class="s2">&quot;addprinc -randkey HTTP/cdh2@JAVACHEN.COM&quot;</span>
kadmin.local -q <span class="s2">&quot;addprinc -randkey HTTP/cdh3@JAVACHEN.COM&quot;</span>
</code></pre></div>
<p>创建完成后，查看：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;listprincs&quot;</span>
</code></pre></div>
<h2 id="4.2-创建keytab文件">4.2 创建keytab文件</h2>

<p>keytab 是包含 principals 和加密 principal key 的文件。</p>

<p>keytab 文件对于每个 host 是唯一的，因为 key 中包含 hostname。keytab 文件用于不需要人工交互和保存纯文本密码，实现到 kerberos 上验证一个主机上的 principal。</p>

<p>因为服务器上可以访问 keytab 文件即可以以 principal 的身份通过 kerberos 的认证，所以，keytab 文件应该被妥善保存，应该只有少数的用户可以访问</p>

<p>创建包含 hdfs principal 和 host principal 的 hdfs keytab：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">xst -norandkey -k hdfs.keytab hdfs/fully.qualified.domain.name host/fully.qualified.domain.name
</code></pre></div>
<p>创建包含 mapred principal 和 host principal 的 mapred keytab：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">xst -norandkey -k mapred.keytab mapred/fully.qualified.domain.name host/fully.qualified.domain.name
</code></pre></div>
<blockquote>
<p><strong>注意</strong>：<br>
上面的方法使用了xst的norandkey参数，有些kerberos不支持该参数。<br>
当不支持该参数时有这样的提示：<code class="prettyprint">Principal -norandkey does not exist.</code>，需要使用下面的方法来生成keytab文件。</p>
</blockquote>

<p>在 cdh1 节点，即 KDC server 节点上执行下面命令：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span><span class="nb">cd</span> /var/kerberos/krb5kdc/

<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;xst  -k hdfs-unmerged.keytab  hdfs/cdh1@JAVACHEN.COM&quot;</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;xst  -k hdfs-unmerged.keytab  hdfs/cdh2@JAVACHEN.COM&quot;</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;xst  -k hdfs-unmerged.keytab  hdfs/cdh3@JAVACHEN.COM&quot;</span>

<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;xst  -k HTTP.keytab  HTTP/cdh1@JAVACHEN.COM&quot;</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;xst  -k HTTP.keytab  HTTP/cdh2@JAVACHEN.COM&quot;</span>
<span class="nv">$ </span>kadmin.local -q <span class="s2">&quot;xst  -k HTTP.keytab  HTTP/cdh3@JAVACHEN.COM&quot;</span>
</code></pre></div>
<p>这样，就会在 <code class="prettyprint">/var/kerberos/krb5kdc/</code> 目录下生成 <code class="prettyprint">hdfs-unmerged.keytab</code> 和 <code class="prettyprint">HTTP.keytab</code> 两个文件，接下来使用 <code class="prettyprint">ktutil</code> 合并者两个文件为 <code class="prettyprint">hdfs.keytab</code>。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span><span class="nb">cd</span> /var/kerberos/krb5kdc/

<span class="nv">$ </span>ktutil
ktutil: rkt hdfs-unmerged.keytab
ktutil: rkt HTTP.keytab
ktutil: wkt hdfs.keytab
</code></pre></div>
<p>使用 klist 显示 hdfs.keytab 文件列表：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>klist -ket  hdfs.keytab
Keytab name: FILE:hdfs.keytab
KVNO Timestamp         Principal
---- ----------------- --------------------------------------------------------
   2 11/13/14 10:40:18 hdfs/cdh1@JAVACHEN.COM <span class="o">(</span>des3-cbc-sha1<span class="o">)</span>
   2 11/13/14 10:40:18 hdfs/cdh1@JAVACHEN.COM <span class="o">(</span>arcfour-hmac<span class="o">)</span>
   2 11/13/14 10:40:18 hdfs/cdh1@JAVACHEN.COM <span class="o">(</span>des-hmac-sha1<span class="o">)</span>
   2 11/13/14 10:40:18 hdfs/cdh1@JAVACHEN.COM <span class="o">(</span>des-cbc-md5<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh2@JAVACHEN.COM <span class="o">(</span>des3-cbc-sha1<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh2@JAVACHEN.COM <span class="o">(</span>arcfour-hmac<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh2@JAVACHEN.COM <span class="o">(</span>des-hmac-sha1<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh2@JAVACHEN.COM <span class="o">(</span>des-cbc-md5<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh3@JAVACHEN.COM <span class="o">(</span>des3-cbc-sha1<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh3@JAVACHEN.COM <span class="o">(</span>arcfour-hmac<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh3@JAVACHEN.COM <span class="o">(</span>des-hmac-sha1<span class="o">)</span>
   4 11/13/14 10:40:18 hdfs/cdh3@JAVACHEN.COM <span class="o">(</span>des-cbc-md5<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh1@JAVACHEN.COM <span class="o">(</span>des3-cbc-sha1<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh1@JAVACHEN.COM <span class="o">(</span>arcfour-hmac<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh1@JAVACHEN.COM <span class="o">(</span>des-hmac-sha1<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh1@JAVACHEN.COM <span class="o">(</span>des-cbc-md5<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh2@JAVACHEN.COM <span class="o">(</span>des3-cbc-sha1<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh2@JAVACHEN.COM <span class="o">(</span>arcfour-hmac<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh2@JAVACHEN.COM <span class="o">(</span>des-hmac-sha1<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh2@JAVACHEN.COM <span class="o">(</span>des-cbc-md5<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh3@JAVACHEN.COM <span class="o">(</span>des3-cbc-sha1<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh3@JAVACHEN.COM <span class="o">(</span>arcfour-hmac<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh3@JAVACHEN.COM <span class="o">(</span>des-hmac-sha1<span class="o">)</span>
   3 11/13/14 10:40:18 HTTP/cdh3@JAVACHEN.COM <span class="o">(</span>des-cbc-md5<span class="o">)</span>
</code></pre></div>
<p>验证是否正确合并了key，使用合并后的keytab，分别使用hdfs和host principals来获取证书。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kinit -k -t hdfs.keytab hdfs/cdh1@JAVACHEN.COM
<span class="nv">$ </span>kinit -k -t hdfs.keytab HTTP/cdh1@JAVACHEN.COM
</code></pre></div>
<p>如果出现错误：<code class="prettyprint">kinit: Key table entry not found while getting initial credentials</code>，<br>
则上面的合并有问题，重新执行前面的操作。</p>

<h2 id="4.3-部署kerberos-keytab文件">4.3 部署kerberos keytab文件</h2>

<p>拷贝 hdfs.keytab 文件到其他节点的 /etc/hadoop/conf 目录</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span><span class="nb">cd</span> /var/kerberos/krb5kdc/

<span class="nv">$ </span>scp hdfs.keytab cdh1:/etc/hadoop/conf
<span class="nv">$ </span>scp hdfs.keytab cdh2:/etc/hadoop/conf
<span class="nv">$ </span>scp hdfs.keytab cdh3:/etc/hadoop/conf
</code></pre></div>
<p>并设置权限，分别在 cdh1、cdh2、cdh3 上执行：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s2">&quot;chown hdfs:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;</span>
<span class="nv">$ </span>ssh cdh2 <span class="s2">&quot;chown hdfs:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;</span>
<span class="nv">$ </span>ssh cdh3 <span class="s2">&quot;chown hdfs:hadoop /etc/hadoop/conf/hdfs.keytab ;chmod 400 /etc/hadoop/conf/hdfs.keytab&quot;</span>
</code></pre></div>
<p>由于 keytab 相当于有了永久凭证，不需要提供密码(如果修改kdc中的principal的密码，则该keytab就会失效)，所以其他用户如果对该文件有读权限，就可以冒充 keytab 中指定的用户身份访问 hadoop，所以 keytab 文件需要确保只对 owner 有读权限(0400)</p>

<h2 id="4.4-修改-hdfs-配置文件">4.4 修改 hdfs 配置文件</h2>

<p>先停止集群：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span><span class="k">for </span>x in <span class="sb">`</span><span class="nb">cd</span> /etc/init.d <span class="p">;</span> ls hive-*<span class="sb">`</span> <span class="p">;</span> <span class="k">do </span>sudo service <span class="nv">$x</span> stop <span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>x in <span class="sb">`</span><span class="nb">cd</span> /etc/init.d <span class="p">;</span> ls impala-*<span class="sb">`</span> <span class="p">;</span> <span class="k">do </span>sudo service <span class="nv">$x</span> stop <span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>x in <span class="sb">`</span><span class="nb">cd</span> /etc/init.d <span class="p">;</span> ls hadoop-*<span class="sb">`</span> <span class="p">;</span> <span class="k">do </span>sudo service <span class="nv">$x</span> stop <span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>x in <span class="sb">`</span><span class="nb">cd</span> /etc/init.d <span class="p">;</span> ls zookeeper-*<span class="sb">`</span> <span class="p">;</span> <span class="k">do </span>sudo service <span class="nv">$x</span> stop <span class="p">;</span> <span class="k">done</span>
</code></pre></div>
<p>在集群中所有节点的 core-site.xml 文件中添加下面的配置:</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>hadoop.security.authentication<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>kerberos<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>hadoop.security.authorization<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>在集群中所有节点的 hdfs-site.xml 文件中添加下面的配置：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.block.access.token.enable<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>  
  <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir.perm<span class="nt">&lt;/name&gt;</span>  
  <span class="nt">&lt;value&gt;</span>700<span class="nt">&lt;/value&gt;</span>  
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.namenode.keytab.file<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>/etc/hadoop/conf/hdfs.keytab<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.namenode.kerberos.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>hdfs/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.namenode.kerberos.https.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>HTTP/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.datanode.address<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>0.0.0.0:1004<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.datanode.http.address<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>0.0.0.0:1006<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.datanode.keytab.file<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>/etc/hadoop/conf/hdfs.keytab<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.datanode.kerberos.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>hdfs/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.datanode.kerberos.https.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>HTTP/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>如果想开启 SSL，请添加（本文不对这部分做说明）：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.http.policy<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>HTTPS_ONLY<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>如果 HDFS 配置了 QJM HA，则需要添加（另外，你还要在 zookeeper 上配置 kerberos）：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.journalnode.keytab.file<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>/etc/hadoop/conf/hdfs.keytab<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.journalnode.kerberos.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>hdfs/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.journalnode.kerberos.internal.spnego.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>HTTP/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>如果配置了 WebHDFS，则添加：</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.webhdfs.enabled<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.web.authentication.kerberos.principal<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>HTTP/_HOST@JAVACHEN.COM<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.web.authentication.kerberos.keytab<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>/etc/hadoop/conf/hdfs.keytab<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div>
<p>配置中有几点要注意的：</p>

<ul>
<li>1. <code class="prettyprint">dfs.datanode.address</code>表示 data transceiver RPC server 所绑定的 hostname 或 IP 地址，如果开启 security，端口号必须小于 <code class="prettyprint">1024</code>(privileged port)，否则的话启动 datanode 时候会报 <code class="prettyprint">Cannot start secure cluster without privileged resources</code> 错误</li>
<li>2. principal 中的 instance 部分可以使用 <code class="prettyprint">_HOST</code> 标记，系统会自动替换它为全称域名</li>
<li>3. 如果开启了 security, hadoop 会对 hdfs block data(由 <code class="prettyprint">dfs.data.dir</code> 指定)做 permission check，方式用户的代码不是调用hdfs api而是直接本地读block data，这样就绕过了kerberos和文件权限验证，管理员可以通过设置 <code class="prettyprint">dfs.datanode.data.dir.perm</code> 来修改 datanode 文件权限，这里我们设置为700</li>
</ul>

<h2 id="4.5-检查集群上的-hdfs-和本地文件的权限">4.5 检查集群上的 HDFS 和本地文件的权限</h2>

<p>请参考 <a href="http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cdh_sg_users_groups_verify.html">Verify User Accounts and Groups in CDH 5 Due to Security</a> 或者 <a href="http://hadoop.apache.org/docs/r2.5.0/hadoop-project-dist/hadoop-common/SecureMode.html">Hadoop in Secure Mode</a>。</p>

<h2 id="4.6-启动-namenode">4.6 启动 NameNode</h2>

<p>启动之前，请确认 JCE jar 已经替换，请参考前面的说明。</p>

<p>在每个节点上获取 root 用户的 ticket，这里 root 为之前创建的 root/admin 的密码。</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ssh cdh1 <span class="s2">&quot;echo root|kinit root/admin&quot;</span>
<span class="nv">$ </span>ssh cdh1 <span class="s2">&quot;echo root|kinit root/admin&quot;</span>
<span class="nv">$ </span>ssh cdh1 <span class="s2">&quot;echo root|kinit root/admin&quot;</span>
</code></pre></div>
<p>获取 cdh1的 ticket：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>kinit -k -t /etc/hadoop/conf/hdfs.keytab hdfs/cdh1@JAVACHEN.COM
</code></pre></div>
<p>如果出现下面异常 <code class="prettyprint">kinit: Password incorrect while getting initial credentials<br>
</code>，则重新导出 keytab 再试试。</p>

<p>然后启动服务，观察日志：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>/etc/init.d/hadoop-hdfs-namenode start
</code></pre></div>
<p>验证 NameNode 是否启动，一是打开 web 界面查看启动状态，一是运行下面命令查看 hdfs：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>hadoop fs -ls /
Found 4 items
drwxrwxrwx   - yarn hadoop          0 2014-06-26 15:24 /logroot
drwxrwxrwt   - hdfs hadoop          0 2014-11-04 10:44 /tmp
drwxr-xr-x   - hdfs hadoop          0 2014-08-10 10:53 /user
drwxr-xr-x   - hdfs hadoop          0 2013-05-20 22:52 /var
</code></pre></div>
<p>如果在你的凭据缓存中没有有效的 kerberos ticket，执行上面命令将会失败，将会出现下面的错误：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">14/11/04 12:08:12 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException:
GSS initiate failed [Caused by GS***ception: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
Bad connection to FS. command aborted. exception: Call to cdh1/192.168.56.121:8020 failed on local exception: java.io.IOException:
javax.security.sasl.SaslException: GSS initiate failed [Caused by GS***ception: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
</code></pre></div>
<h2 id="4.6-启动datanode">4.6 启动DataNode</h2>

<p>DataNode 需要通过 JSVC 启动。首先检查是否安装了 JSVC 命令，然后配置环境变量。</p>

<p>在 cdh1 节点查看是否安装了 JSVC：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ls /usr/lib/bigtop-utils/
bigtop-detect-classpath  bigtop-detect-javahome  bigtop-detect-javalibs  jsvc
</code></pre></div>
<p>然后编辑 <code class="prettyprint">/etc/default/hadoop-hdfs-datanode</code>，取消对下面的注释并添加一行设置 <code class="prettyprint">JSVC_HOME</code>，修改如下：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">export </span><span class="nv">HADOOP_SECURE_DN_USER</span><span class="o">=</span>hdfs
<span class="nb">export </span><span class="nv">HADOOP_SECURE_DN_PID_DIR</span><span class="o">=</span>/var/run/hadoop-hdfs
<span class="nb">export </span><span class="nv">HADOOP_SECURE_DN_LOG_DIR</span><span class="o">=</span>/var/log/hadoop-hdfs

<span class="nb">export </span><span class="nv">JSVC_HOME</span><span class="o">=</span>/usr/lib/bigtop-utils
</code></pre></div>
<p>将该文件同步到其他节点：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>scp /etc/default/hadoop-hdfs-datanode cdh2:/etc/default/hadoop-hdfs-datanode
<span class="nv">$ </span>scp /etc/default/hadoop-hdfs-datanode cdh3:/etc/default/hadoop-hdfs-datanode
</code></pre></div>
<p>分别在 cdh2、cdh3 获取 ticket 然后启动服务：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#root 为 root/admin 的密码</span>
<span class="nv">$ </span>ssh cdh1 <span class="s2">&quot;kinit -k -t /etc/hadoop/conf/hdfs.keytab hdfs/cdh1@JAVACHEN.COM; service hadoop-hdfs-datanode start&quot;</span>
<span class="nv">$ </span>ssh cdh2 <span class="s2">&quot;kinit -k -t /etc/hadoop/conf/hdfs.keytab hdfs/cdh2@JAVACHEN.COM; service hadoop-hdfs-datanode start&quot;</span>
<span class="nv">$ </span>ssh cdh3 <span class="s2">&quot;kinit -k -t /etc/hadoop/conf/hdfs.keytab hdfs/cdh3@JAVACHEN.COM; service hadoop-hdfs-datanode start&quot;</span>
</code></pre></div>
<p>观看 cdh1 上 NameNode 日志，出现下面日志表示 DataNode 启动成功：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">14/11/04 17:21:41 INFO security.UserGroupInformation:
Login successful for user hdfs/cdh2@JAVACHEN.COM using keytab file /etc/hadoop/conf/hdfs.keytab
</code></pre></div>
<h1 id="5.-其他">5. 其他</h1>

<h2 id="5.1-批量生成-keytab">5.1 批量生成 keytab</h2>

<p>为了方便批量生成 keytab，写了一个脚本，如下：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#!/bin/bash</span>

<span class="nv">DNS</span><span class="o">=</span>LASHOU.COM
<span class="nv">hostname</span><span class="o">=</span><span class="sb">`</span>hostname -i<span class="sb">`</span>

yum install krb5-server krb5-libs krb5-auth-dialog krb5-workstation  -y
rm -rf /var/kerberos/krb5kdc/*.keytab /var/kerberos/krb5kdc/prin*

kdb5_util create -r LASHOU.COM -s

chkconfig --level 35 krb5kdc on
chkconfig --level 35 kadmin on
service krb5kdc restart
service kadmin restart

<span class="nb">echo</span> -e <span class="s2">&quot;root\nroot&quot;</span> <span class="p">|</span> kadmin.local -q <span class="s2">&quot;addprinc root/admin&quot;</span>

<span class="k">for </span>host in  <span class="sb">`</span>cat /etc/hosts<span class="p">|</span>grep 10<span class="p">|</span>grep -v <span class="nv">$hostname</span><span class="p">|</span>awk <span class="s1">&#39;{print $2}&#39;</span><span class="sb">`</span> <span class="p">;</span><span class="k">do</span>
<span class="k">  for </span>user in hdfs hive<span class="p">;</span> <span class="k">do</span>
<span class="k">    </span>kadmin.local -q <span class="s2">&quot;addprinc -randkey $user/$host@$DNS&quot;</span>
    kadmin.local -q <span class="s2">&quot;xst -k /var/kerberos/krb5kdc/$user-un.keytab $user/$host@$DNS&quot;</span>
  <span class="k">done</span>
<span class="k">  for </span>user in HTTP lashou yarn mapred impala zookeeper sentry llama zkcli <span class="p">;</span> <span class="k">do</span>
<span class="k">    </span>kadmin.local -q <span class="s2">&quot;addprinc -randkey $user/$host@$DNS&quot;</span>
    kadmin.local -q <span class="s2">&quot;xst -k /var/kerberos/krb5kdc/$user.keytab $user/$host@$DNS&quot;</span>
  <span class="k">done</span>
<span class="k">done</span>

<span class="nb">cd</span> /var/kerberos/krb5kdc/
<span class="nb">echo</span> -e <span class="s2">&quot;rkt lashou.keytab\nrkt hdfs-un.keytab\nrkt HTTP.keytab\nwkt hdfs.keytab&quot;</span> <span class="p">|</span> ktutil
<span class="nb">echo</span> -e <span class="s2">&quot;rkt lashou.keytab\nrkt hive-un.keytab\nwkt hive.keytab&quot;</span> <span class="p">|</span> ktutil

<span class="c">#kerberos 重新初始化之后，还需要添加下面代码用于集成 ldap</span>

kadmin.local -q <span class="s2">&quot;addprinc ldapadmin@JAVACHEN.COM&quot;</span>
kadmin.local -q <span class="s2">&quot;addprinc -randkey ldap/cdh1@JAVACHEN.COM&quot;</span>
kadmin.local -q <span class="s2">&quot;ktadd -k /etc/openldap/ldap.keytab ldap/cdh1@JAVACHEN.COM&quot;</span>

<span class="c">#如果安装了 openldap ，重启 slapd</span>
/etc/init.d/slapd restart

<span class="c">#测试 ldap 是否可以正常使用</span>
ldapsearch -x -b <span class="s1">&#39;dc=javachen,dc=com&#39;</span>
</code></pre></div>
<p>以下脚本用于在每个客户端上获得 root/admin 的 ticket，其密码为 root：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#!/bin/sh</span>

<span class="k">for </span>node in 56.121 56.122 56.123 <span class="p">;</span><span class="k">do</span>
<span class="k">  </span><span class="nb">echo</span> <span class="s2">&quot;========10.168.$node========&quot;</span>
  ssh 192.168.<span class="nv">$node</span> <span class="s1">&#39;echo root|kinit root/admin&#39;</span>
<span class="k">done</span>
</code></pre></div>
<h2 id="5.2-管理集群脚本">5.2 管理集群脚本</h2>

<p>另外，为了方便管理集群，在 cdh1 上创建一个 shell 脚本用于批量管理集群，脚本如下（保存为 <code class="prettyprint">manager_cluster.sh</code>）：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#!/bin/bash</span>

<span class="nv">role</span><span class="o">=</span><span class="nv">$1</span>
<span class="nb">command</span><span class="o">=</span><span class="nv">$2</span>

<span class="nv">dir</span><span class="o">=</span><span class="nv">$role</span>

<span class="k">if</span> <span class="o">[</span> X<span class="s2">&quot;$role&quot;</span> <span class="o">==</span> X<span class="s2">&quot;hdfs&quot;</span> <span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="k">  </span><span class="nv">dir</span><span class="o">=</span>hadoop
<span class="k">fi</span>

<span class="k">if</span> <span class="o">[</span> X<span class="s2">&quot;$role&quot;</span> <span class="o">==</span> X<span class="s2">&quot;yarn&quot;</span> <span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="k">        </span><span class="nv">dir</span><span class="o">=</span>hadoop
<span class="k">fi</span>

<span class="k">if</span> <span class="o">[</span> X<span class="s2">&quot;$role&quot;</span> <span class="o">==</span> X<span class="s2">&quot;mapred&quot;</span> <span class="o">]</span><span class="p">;</span><span class="k">then</span>
<span class="k">        </span><span class="nv">dir</span><span class="o">=</span>hadoop
<span class="k">fi</span>

<span class="k">for </span>node in 56.121 56.122 56.123 <span class="p">;</span><span class="k">do</span>
<span class="k">  </span><span class="nb">echo</span> <span class="s2">&quot;========192.168.$node========&quot;</span>
  ssh 192.168.<span class="nv">$node</span> <span class="s1">&#39;</span>
<span class="s1">    #先获取 root/admin 的凭证</span>
<span class="s1">    echo root|kinit root/admin</span>
<span class="s1">    host=`hostname -f| tr &quot;[:upper:]&quot; &quot;[:lower:]&quot;`</span>
<span class="s1">    path=&quot;&#39;</span><span class="nv">$role</span><span class="s1">&#39;/$host&quot;</span>
<span class="s1">    #echo $path</span>
<span class="s1">    principal=`klist -k /etc/&#39;</span><span class="nv">$dir</span><span class="s1">&#39;/conf/&#39;</span><span class="nv">$role</span><span class="s1">&#39;.keytab | grep $path | head -n1 | cut -d &quot; &quot; -f5`</span>
<span class="s1">    #echo $principal</span>
<span class="s1">    if [ X&quot;$principal&quot; == X ]; then</span>
<span class="s1">      principal=`klist -k /etc/&#39;</span><span class="nv">$dir</span><span class="s1">&#39;/conf/&#39;</span><span class="nv">$role</span><span class="s1">&#39;.keytab | grep $path | head -n1 | cut -d &quot; &quot; -f4`</span>
<span class="s1">      if [ X&quot;$principal&quot; == X ]; then</span>
<span class="s1">            echo &quot;Failed to get hdfs Kerberos principal&quot;</span>
<span class="s1">            exit 1</span>
<span class="s1">      fi</span>
<span class="s1">    fi</span>
<span class="s1">    kinit -r 24l -kt /etc/&#39;</span><span class="nv">$dir</span><span class="s1">&#39;/conf/&#39;</span><span class="nv">$role</span><span class="s1">&#39;.keytab $principal</span>
<span class="s1">    if [ $? -ne 0 ]; then</span>
<span class="s1">        echo &quot;Failed to login as hdfs by kinit command&quot;</span>
<span class="s1">        exit 1</span>
<span class="s1">    fi</span>
<span class="s1">    kinit -R</span>
<span class="s1">    for src in `ls /etc/init.d|grep &#39;</span><span class="nv">$role</span><span class="s1">&#39;`;do service $src &#39;</span><span class="nv">$command</span><span class="s1">&#39;; done</span>
<span class="s1">  &#39;</span>
<span class="k">done</span>
</code></pre></div>
<p>使用方法为：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>sh manager_cluster.sh hdfs start <span class="c">#启动 hdfs 用户管理的服务</span>
<span class="nv">$ </span>sh manager_cluster.sh yarn start <span class="c">#启动 yarn 用户管理的服务</span>
<span class="nv">$ </span>sh manager_cluster.sh mapred start <span class="c">#启动 mapred 用户管理的服务</span>

<span class="nv">$ </span>sh manager_cluster.sh hdfs status <span class="c"># 在每个节点上获取 hdfs 的 ticket，然后可以执行其他操作，如批量启动 datanode 等等</span>
</code></pre></div>
<h2 id="5.3-使用-java-代码测试-kerberos">5.3 使用 java 代码测试 kerberos</h2>

<p>在 hdfs 中集成 kerberos 之前，可以先使用下面代码(Krb.java)进行测试：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">com.sun.security.auth.module.Krb5LoginModule</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">javax.security.auth.Subject</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.File</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.FileInputStream</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.InputStream</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.HashMap</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Map</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Krb</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">loginImpl</span><span class="o">(</span><span class="kd">final</span> <span class="n">String</span> <span class="n">propertiesFileName</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;NB: system property to specify the krb5 config: [java.security.krb5.conf]&quot;</span><span class="o">);</span>
        <span class="c1">//System.setProperty(&quot;java.security.krb5.conf&quot;, &quot;/etc/krb5.conf&quot;);</span>

        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">System</span><span class="o">.</span><span class="na">getProperty</span><span class="o">(</span><span class="s">&quot;java.version&quot;</span><span class="o">));</span>

        <span class="n">System</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;sun.security.krb5.debug&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>

        <span class="kd">final</span> <span class="n">Subject</span> <span class="n">subject</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Subject</span><span class="o">();</span>

        <span class="kd">final</span> <span class="n">Krb5LoginModule</span> <span class="n">krb5LoginModule</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Krb5LoginModule</span><span class="o">();</span>
        <span class="kd">final</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">optionMap</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span><span class="n">String</span><span class="o">&gt;();</span>

        <span class="k">if</span> <span class="o">(</span><span class="n">propertiesFileName</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="c1">//optionMap.put(&quot;ticketCache&quot;, &quot;/tmp/krb5cc_1000&quot;);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;keyTab&quot;</span><span class="o">,</span> <span class="s">&quot;/etc/krb5.keytab&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;principal&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">);</span> <span class="c1">// default realm</span>

            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;doNotPrompt&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;refreshKrb5Config&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;useTicketCache&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;renewTGT&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;useKeyTab&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;storeKey&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;isInitiator&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
        <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
            <span class="n">File</span> <span class="n">f</span> <span class="o">=</span> <span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="n">propertiesFileName</span><span class="o">);</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;======= loading property file [&quot;</span><span class="o">+</span><span class="n">f</span><span class="o">.</span><span class="na">getAbsolutePath</span><span class="o">()+</span><span class="s">&quot;]&quot;</span><span class="o">);</span>
            <span class="n">Properties</span> <span class="n">p</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>
            <span class="n">InputStream</span> <span class="n">is</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FileInputStream</span><span class="o">(</span><span class="n">f</span><span class="o">);</span>
            <span class="k">try</span> <span class="o">{</span>
                <span class="n">p</span><span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="n">is</span><span class="o">);</span>
            <span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
                <span class="n">is</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
            <span class="o">}</span>
            <span class="n">optionMap</span><span class="o">.</span><span class="na">putAll</span><span class="o">((</span><span class="n">Map</span><span class="o">)</span><span class="n">p</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="n">optionMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;debug&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span> <span class="c1">// switch on debug of the Java implementation</span>

        <span class="n">krb5LoginModule</span><span class="o">.</span><span class="na">initialize</span><span class="o">(</span><span class="n">subject</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span><span class="n">String</span><span class="o">&gt;(),</span> <span class="n">optionMap</span><span class="o">);</span>

        <span class="kt">boolean</span> <span class="n">loginOk</span> <span class="o">=</span> <span class="n">krb5LoginModule</span><span class="o">.</span><span class="na">login</span><span class="o">();</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;======= login:  &quot;</span> <span class="o">+</span> <span class="n">loginOk</span><span class="o">);</span>

        <span class="kt">boolean</span> <span class="n">commitOk</span> <span class="o">=</span> <span class="n">krb5LoginModule</span><span class="o">.</span><span class="na">commit</span><span class="o">();</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;======= commit: &quot;</span> <span class="o">+</span> <span class="n">commitOk</span><span class="o">);</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;======= Subject: &quot;</span> <span class="o">+</span> <span class="n">subject</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;A property file with the login context can be specified as the 1st and the only paramater.&quot;</span><span class="o">);</span>
        <span class="kd">final</span> <span class="n">Krb</span> <span class="n">krb</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Krb</span><span class="o">();</span>
        <span class="n">krb</span><span class="o">.</span><span class="na">loginImpl</span><span class="o">(</span><span class="n">args</span><span class="o">.</span><span class="na">length</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">?</span> <span class="kc">null</span> <span class="o">:</span> <span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">]);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>
<p>创建一个配置文件krb5.properties：</p>
<div class="highlight"><pre><code class="language-properties" data-lang="properties"><span class="na">keyTab</span><span class="o">=</span><span class="s">/etc/hadoop/conf/hdfs.keytab</span>
<span class="na">principal</span><span class="o">=</span><span class="s">hdfs/cdh1@JAVACHEN.COM</span>

<span class="na">doNotPrompt</span><span class="o">=</span><span class="s">true</span>
<span class="na">refreshKrb5Config</span><span class="o">=</span><span class="s">true</span>
<span class="na">useTicketCache</span><span class="o">=</span><span class="s">true</span>
<span class="na">renewTGT</span><span class="o">=</span><span class="s">true</span>
<span class="na">useKeyTab</span><span class="o">=</span><span class="s">true</span>
<span class="na">storeKey</span><span class="o">=</span><span class="s">true</span>
<span class="na">isInitiator</span><span class="o">=</span><span class="s">true</span>
</code></pre></div>
<p>编译 java 代码并运行：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># 先销毁当前 ticket</span>

<span class="nv">$ </span>kdestroy

<span class="nv">$ </span>javac Krb.java

<span class="nv">$ </span>java -cp . Krb ./krb5.properties
</code></pre></div>
<h1 id="6.-总结">6. 总结</h1>

<p>本文介绍了 CDH Hadoop 集成 kerberos 认证的过程，其中主要需要注意以下几点：</p>

<ul>
<li>1. 配置 hosts，<code class="prettyprint">hostname</code> 请使用小写。</li>
<li>2. 确保 kerberos 客户端和服务端连通</li>
<li>3. 替换 JRE 自带的 JCE jar 包</li>
<li>4. 为 DataNode 设置运行用户并配置 <code class="prettyprint">JSVC_HOME</code></li>
<li>5. 启动服务前，先获取 ticket 再运行相关命令</li>
</ul>

<p>接下来就是配置 Hadoop 集群中其他服务以集成 kerberos 认证，由于篇幅原因，后面再做说明。</p>

<h1 id="7.-参考文章">7. 参考文章</h1>

<ul>
<li><a href="https://github.com/zouhc/MyHadoop/blob/master/doc/Hadoop%E7%9A%84kerberos%E7%9A%84%E5%AE%9E%E8%B7%B5%E9%83%A8%E7%BD%B2.md">Hadoop的kerberos的实践部署</a></li>
<li><a href="http://blog.chinaunix.net/uid-1838361-id-3243243.html">hadoop 添加kerberos认证</a></li>
<li><a href="http://blog.csdn.net/lalaguozhe/article/details/11570009">YARN &amp; HDFS2 安装和配置Kerberos</a></li>
<li><a href="http://blog.godatadriven.com/kerberos_kdc_install.html">Kerberos basics and installing a KDC</a></li>
<li><a href="http://www.wuzesheng.com/?p=2345">Hadoop, Hbase, Zookeeper安全实践</a></li>
</ul>
</div>

      <!--
      <div id="pay" style="text-align:center;">
        ----EOF-----
        <br>
        <section>
  <h4>Sponsor</h4>
	<img src="http://xiaotian120.qiniudn.com/images/alipay.png" width="150/">
  <p class="small">觉得此博客对你有帮助，支付宝扫码赞助吧</p>
</section>

      </div>
      -->
      <p class="meta">
      	
            Categories:
      	    
          	<a class="btn btn-default btn-xs" href="/categories.html#hadoop">hadoop</a>
          
      	

      	
            Tags:
      	    
          	<a class="btn btn-default btn-xs" href="/tags.html#hadoop">hadoop</a>
          
          	<a class="btn btn-default btn-xs" href="/tags.html#kerberos">kerberos</a>
          
          	<a class="btn btn-default btn-xs" href="/tags.html#cdh">cdh</a>
          
      	
      </p>
	</article>

	<ul class="pager">
	  
	  <li class="previous"><a class="btn btn-xs" href="/2014/10/30/install-postgresql-on-mac-using-homebrew" title="Mac上使用homebrew安装PostgreSql">&larr; Prev</a></li>
	  
	  
	  <li class="next"><a class="btn btn-xs" href="/2014/11/05/config-kerberos-in-cdh-yarn" title="YARN配置Kerberos认证">Next &rarr;</a></li>
	  
	</ul>

  
<div id="comments">
  <div class="ds-thread" data-thread-key="/2014/11/04/config-kerberos-in-cdh-hdfs"  data-title="HDFS配置Kerberos认证 - 天松的个人博客"></div>
</div>



</div>

        </div>
      </div>

      <footer class="footer text-center">
  <p>&copy; 2009-2015 <a href="/" target="_blank" title="86后，工作在深圳；Java程序员、Hadoop工程师；主要关注Java、Scala、Hadoop、Kettle、关注大数据处理技术。">天松</a>. With Help from <a href="//jekyllrb.com/" target="_blank" title="Transform your plain text into static websites and blogs.">Jekyll</a> and <a href="//getbootstrap.com/" target="_blank" title="Bootstrap is the most popular HTML, CSS, and JS framework for developing responsive, mobile first projects on the web.">Bootstrap</a>, theme from <a href="http://havee.me/" target="_blank" title="http://havee.me/">Havee</a>.

  <span style="float:right;"><a href="/about.html">About</a></span>

	
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254098866'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1254098866' type='text/javascript'%3E%3C/script%3E"));</script>




  </p>
  <div id="toTop" style="display: block;">
    <a href="#">▲</a><a href="#footer">▼</a>
  </div>
</footer>

    </div>

    <script src="/static/js/jquery.min.js"></script>
    <script src="/static/js/bootstrap.min.js"></script>
    <script src="/static/js/core.js"></script>

    
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254098866'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1254098866' type='text/javascript'%3E%3C/script%3E"));</script>




    
    <!-- duoshuo Begin -->
    <script type="text/javascript">
      var duoshuoQuery = {short_name:"sunshine1987"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
    </script>
    <!-- duoshuo End -->
    
  </body>
</html>
